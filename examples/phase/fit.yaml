# fit.yaml

trainer:
  precision: 16-mixed
  gradient_clip_val: 1.0
  max_epochs: 100
  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      save_dir: ./logs/
      log_model: all
  callbacks:
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        filename: best_model
        mode: min
        save_top_k: 1
        save_last: true
        dirpath: ./checkpoints/
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        monitor: val_loss
        patience: 10
        mode: min
        verbose: true

optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 0.001

lr_scheduler: 
  class_path: lib.training.optimisation.lr_schedulers.LinearWarmupAndInverseSqrtDecayLR
  init_args: 
    warmup_epochs: 10

data:
  class_path: lib.data.datamodules.netCDFDataModule
  init_args:
    train_paths: 
      - data/train.nc
    validate_paths: 
      - data/validation.nc
    predict_paths:
      - data/test.nc
    target_variables:
      - 'on'
      - 'off'